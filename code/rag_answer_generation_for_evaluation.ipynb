{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8365658,"sourceType":"datasetVersion","datasetId":4972616}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers accelerate bitsandbytes langchain langchain_experimental  sentence-transformers faiss-gpu pypdf ragatouille","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-09T14:56:40.763660Z","iopub.execute_input":"2024-05-09T14:56:40.764329Z","iopub.status.idle":"2024-05-09T14:57:26.834085Z","shell.execute_reply.started":"2024-05-09T14:56:40.764294Z","shell.execute_reply":"2024-05-09T14:57:26.832939Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nCollecting langchain\n  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\nCollecting langchain_experimental\n  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.2.0)\nCollecting ragatouille\n  Downloading ragatouille-0.0.8.post2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nCollecting langchain-community<0.1,>=0.0.38 (from langchain)\n  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\nCollecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nCollecting colbert-ai==0.2.19 (from ragatouille)\n  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting fast-pytorch-kmeans==0.2.0.1 (from ragatouille)\n  Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl.metadata (1.1 kB)\nCollecting llama-index>=0.7 (from ragatouille)\n  Downloading llama_index-0.10.35-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: onnx<2.0.0,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from ragatouille) (1.16.0)\nRequirement already satisfied: srsly==2.4.8 in /opt/conda/lib/python3.10/site-packages (from ragatouille) (2.4.8)\nCollecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n  Downloading voyager-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\nCollecting bitarray (from colbert-ai==0.2.19->ragatouille)\n  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (2.18.0)\nRequirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (3.0.3)\nCollecting git-python (from colbert-ai==0.2.19->ragatouille)\n  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.0)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.11.1.1)\nRequirement already satisfied: ujson in /opt/conda/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (5.9.0)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (11.4.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from srsly==2.4.8->ragatouille) (2.0.10)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\nCollecting packaging>=20.0 (from transformers)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_agent_openai-0.2.4-py3-none-any.whl.metadata (678 bytes)\nCollecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core<0.11.0,>=0.10.35 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_core-0.10.36-py3-none-any.whl.metadata (3.7 kB)\nCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl.metadata (603 bytes)\nCollecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_llms_openai-0.1.18-py3-none-any.whl.metadata (559 bytes)\nCollecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\nCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\nCollecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_readers_file-0.1.22-py3-none-any.whl.metadata (5.3 kB)\nCollecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (3.20.3)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\nCollecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index>=0.7->ragatouille)\n  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.2.14)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (0.27.0)\nCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille)\n  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.5.8)\nCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (2.1.4)\nCollecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.14.1)\nCollecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nCollecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index>=0.7->ragatouille)\n  Downloading llama_parse-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.2)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask->colbert-ai==0.2.19->ragatouille) (1.7.0)\nRequirement already satisfied: gitpython in /opt/conda/lib/python3.10/site-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.41)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (2.5)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (4.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (0.14.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index>=0.7->ragatouille) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (2023.4)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.35->llama-index>=0.7->ragatouille) (1.16.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_experimental-0.0.58-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading ragatouille-0.0.8.post2-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl (8.8 kB)\nDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index-0.10.35-py3-none-any.whl (6.9 kB)\nDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading voyager-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_agent_openai-0.2.4-py3-none-any.whl (13 kB)\nDownloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\nDownloading llama_index_core-0.10.36-py3-none-any.whl (15.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading llama_index_embeddings_openai-0.1.9-py3-none-any.whl (6.0 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\nDownloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading llama_index_llms_openai-0.1.18-py3-none-any.whl (11 kB)\nDownloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\nDownloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\nDownloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_file-0.1.22-py3-none-any.whl (36 kB)\nDownloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\nDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\nDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading llama_parse-0.4.2-py3-none-any.whl (7.6 kB)\nDownloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-1.27.0-py3-none-any.whl (314 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: colbert-ai\n  Building wheel for colbert-ai (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114761 sha256=744c66b996a22edcff49a793b4516196eda5921f60b9eef082d7387f13d49d00\n  Stored in directory: /root/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\nSuccessfully built colbert-ai\nInstalling collected packages: striprtf, faiss-gpu, dirtyjson, bitarray, voyager, packaging, orjson, nltk, faiss-cpu, beautifulsoup4, tiktoken, openai, llamaindex-py-client, langsmith, git-python, fast-pytorch-kmeans, bitsandbytes, llama-index-legacy, llama-index-core, langchain-core, sentence-transformers, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, langchain-community, colbert-ai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, langchain_experimental, llama-index-question-gen-openai, llama-index, ragatouille\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: beautifulsoup4\n    Found existing installation: beautifulsoup4 4.12.2\n    Uninstalling beautifulsoup4-4.12.2:\n      Successfully uninstalled beautifulsoup4-4.12.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed beautifulsoup4-4.12.3 bitarray-2.9.2 bitsandbytes-0.43.1 colbert-ai-0.2.19 dirtyjson-1.0.8 faiss-cpu-1.8.0 faiss-gpu-1.7.2 fast-pytorch-kmeans-0.2.0.1 git-python-1.0.3 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.1 langchain_experimental-0.0.58 langsmith-0.1.56 llama-index-0.10.35 llama-index-agent-openai-0.2.4 llama-index-cli-0.1.12 llama-index-core-0.10.36 llama-index-embeddings-openai-0.1.9 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.18 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.22 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.2 llamaindex-py-client-0.1.19 nltk-3.8.1 openai-1.27.0 orjson-3.10.3 packaging-23.2 ragatouille-0.0.8.post2 sentence-transformers-2.7.0 striprtf-0.0.26 tiktoken-0.6.0 voyager-2.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM\nimport transformers\n# for LLM\nfrom torch import cuda, bfloat16\nfrom transformers import BitsAndBytesConfig\n# For vector database\nfrom langchain_community.document_loaders import PyPDFDirectoryLoader\nfrom sentence_transformers import SentenceTransformer\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom langchain.vectorstores import FAISS\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.embeddings.fastembed import FastEmbedEmbeddings\nfrom langchain_community.vectorstores.utils import DistanceStrategy\nfrom ragatouille import RAGPretrainedModel\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom langchain.retrievers.document_compressors import EmbeddingsFilter\nfrom langchain.document_transformers import EmbeddingsRedundantFilter\nfrom langchain.retrievers.document_compressors import DocumentCompressorPipeline\nfrom langchain.retrievers import ContextualCompressionRetriever\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport logging\n\n# Set the logging level to suppress warnings\nlogging.basicConfig(level=logging.ERROR)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:57:26.836346Z","iopub.execute_input":"2024-05-09T14:57:26.836736Z","iopub.status.idle":"2024-05-09T14:57:41.657777Z","shell.execute_reply.started":"2024-05-09T14:57:26.836694Z","shell.execute_reply":"2024-05-09T14:57:41.656995Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ndef create_knowledgebase(folder_path, embedding_model, chunk_size = 1000, chunk_overlap = 200):\n  print(f\"Loading pdf from {data_loc}...\")\n  loader = PyPDFDirectoryLoader(data_loc)\n  docs = loader.load()\n  # Splitter specific to embedding model\n  # EMBEDDING_MODEL_NAME_small = \"thenlper/gte-small\"\n\n  text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n          AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME),\n          chunk_size=chunk_size,\n          chunk_overlap=chunk_overlap,\n          add_start_index=True,\n          strip_whitespace=True\n      )\n  # text_splitter = SemanticChunker(embedding_model, breakpoint_threshold_type=\"percentile\")\n  # splits = text_splitter.create_documents([d.page_content for d in docs])\n  print(\"Splitting documents...\")\n  splits = text_splitter.split_documents(docs)\n  print(\"Creating vector database\")\n  KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n      splits, embedding_model, distance_strategy=DistanceStrategy.COSINE\n  )\n  print(\"Successfully created knowledge base\")\n  return KNOWLEDGE_VECTOR_DATABASE\n\ndata_loc = \"/kaggle/input/rag-dataset-1/ASR_Papers-20240509T054617Z-001/ASR_Papers\"\nEMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\nchunk_size = 1000\nchunk_overlap = 200\nembedding_model = HuggingFaceEmbeddings(\n    model_name=EMBEDDING_MODEL_NAME,\n    multi_process=True,\n    model_kwargs={\"device\": \"cuda\"},\n    encode_kwargs={\"normalize_embeddings\": True},\n)\n# Knowledge database creation\nKNOWLEDGE_VECTOR_DATABASE = create_knowledgebase(data_loc, embedding_model, chunk_size=chunk_size, chunk_overlap=chunk_overlap )\n\n# for Compression filters\nretriever = KNOWLEDGE_VECTOR_DATABASE.as_retriever(search_kwargs={\"k\": 20, \"include_metadata\": True})\nsplitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0, separator=\". \")\nredundant_filter = EmbeddingsRedundantFilter(embeddings=embedding_model)\nrelevant_filter = EmbeddingsFilter(embeddings=embedding_model,k=5) # either k=ineteger or similarity_threshold=0.76\npipeline_compressor = DocumentCompressorPipeline(\n    transformers=[splitter, redundant_filter, relevant_filter]\n)\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=pipeline_compressor, base_retriever=retriever\n)\n\n# for both compression and reranking\nrelevant_filter_1 = EmbeddingsFilter(embeddings=embedding_model,k=10) # either k=ineteger or similarity_threshold=0.76\npipeline_compressor_1 = DocumentCompressorPipeline(\n    transformers=[splitter, redundant_filter, relevant_filter_1]\n)\ncompression_retriever_1 = ContextualCompressionRetriever(\n    base_compressor=pipeline_compressor_1, base_retriever=retriever\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:57:41.659068Z","iopub.execute_input":"2024-05-09T14:57:41.659564Z","iopub.status.idle":"2024-05-09T14:58:27.279077Z","shell.execute_reply.started":"2024-05-09T14:57:41.659537Z","shell.execute_reply":"2024-05-09T14:58:27.278085Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20536bf4610a4ec8a44f5d45e53a9df9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19990584dc09479f994f20df8c5e59d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4b8c7066eec499b99f911a1eea587f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fa7f91cf3264b0fb7085c51c3a2fa1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7a7f7c8b8014ecd9edc47d8ed7c0536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099da70ba6ca47aa880ebd30c3f4e091"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a13b8a07600444d8f9522fb71e4cc99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63260939f0ca4b0d93f71f78b7c90c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3846130fdcc7430baba27405c6d66dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54c9cbc0bf0d4a1bb0f18178c893efab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"316272a70e4a49c3ba413e6ab80d385a"}},"metadata":{}},{"name":"stdout","text":"Loading pdf from /kaggle/input/rag-dataset-1/ASR_Papers-20240509T054617Z-001/ASR_Papers...\nSplitting documents...\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"Creating vector database\nSuccessfully created knowledge base\n","output_type":"stream"}]},{"cell_type":"code","source":"access_token = \"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\"\nmodel_id_map = {\"llama2\":\"meta-llama/Llama-2-7b-chat-hf\",\n                \"mistral\":\"mistralai/Mistral-7B-Instruct-v0.2\",\n                \"gemma\":\"google/gemma-1.1-7b-it\",\n                \"llama3\":\"meta-llama/Meta-Llama-3-8B-Instruct\"}\nmodel_id = model_id_map[\"llama3\"]\n\nprint(\"Loading tokenizer\")\ntokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token)\n\nbnb_config = transformers.BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=bfloat16\n)\nprint(\"Loading LLM\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    device_map=\"auto\",\n    token=access_token,\n    quantization_config=bnb_config,\n\n)\nprint(\"Creating pipeline\")\nllm_pipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    max_new_tokens=500\n\n)\nprint(\"Loading re-ranker\")\nRERANKER = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T14:58:27.281087Z","iopub.execute_input":"2024-05-09T14:58:27.281392Z","iopub.status.idle":"2024-05-09T15:01:10.934060Z","shell.execute_reply.started":"2024-05-09T14:58:27.281367Z","shell.execute_reply":"2024-05-09T15:01:10.933191Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Loading tokenizer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503bdf928808480caa507e014df3925f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"879872e1546148dbb6f784204a8fafb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"955501f70e614e8ba0a0353d0ad78620"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"Loading LLM\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31c172cb4a74b228973f3fe67df3588"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c9d01bd0584ba7980ab405bf01f832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb9e053ecb2b488593fe6fec197347c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c985a9f5c991469c8e76b020dc7f83d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62fb1066fada48b6b549def2d3c0f55c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d9388c8911493595deea1019b21a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2198d1c249394a8c801b0e5f5556fb38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68526f82b3004dccbea4e2aba654e576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a03d7b1a064e83bafdcfe44cec43f6"}},"metadata":{}},{"name":"stdout","text":"Creating pipeline\n","output_type":"stream"},{"name":"stderr","text":"2024-05-09 15:00:58.929980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-09 15:00:58.930086: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-09 15:00:59.043327: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Loading re-ranker\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7165898f53144d9a97c14518e83dd670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5141108db24c46daaed1e6d5ab612703"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2658ed00a28949f486a010234f3030b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cbad81d464847d985e5466b8f7d9559"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c4516513d464abe9a7e929cb59863dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b3cd528e2343ef9670b19ef8df7126"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"049bcc7ff2d04956a3615cf970aea83e"}},"metadata":{}}]},{"cell_type":"code","source":"pip install -i https://pypi.org/simple/ bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_in_chat_format = [\n    {\n        \"role\": \"system\",\n        \"content\": \"\"\"Use the information contained in the context along with the knowledge you have and give a comprehensive answer to the question.\nRespond only to the question asked.\"\"\",\n    },\n    {\n        \"role\": \"user\",\n        \"content\": \"\"\"Context:\n{context}\n---\nNow here is the question you need to answer.\n\nQuestion: {question}\"\"\",\n    },\n]\nRAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n)\nprint(RAG_PROMPT_TEMPLATE)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:01:10.935289Z","iopub.execute_input":"2024-05-09T15:01:10.935600Z","iopub.status.idle":"2024-05-09T15:01:10.989329Z","shell.execute_reply.started":"2024-05-09T15:01:10.935573Z","shell.execute_reply":"2024-05-09T15:01:10.988355Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nUse the information contained in the context along with the knowledge you have and give a comprehensive answer to the question.\nRespond only to the question asked.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nContext:\n{context}\n---\nNow here is the question you need to answer.\n\nQuestion: {question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport openpyxl\n\ndef writing_in_json(reranking , compression_filter, search_type,user_query,want_to_see_llm_response_without_rag):\n    relevant_docs = []  # Initialize relevant_docs as an empty list\n    retrieved_docs = [] \n    if want_to_see_llm_response_without_rag:\n#         print(\"####################### Answer without RAG #######################\")\n        answer = llm_pipeline(user_query)[0][\"generated_text\"]\n        # print(answer_wo_rag)\n    else :\n      if reranking and not compression_filter:\n          if search_type == 'similarity':\n              # Similarity search\n              retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=20)\n          elif search_type == 'mmr':\n              # Maximum marginal relevance search\n              retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.max_marginal_relevance_search(query=user_query, k=20)\n          retrieved_docs = [doc.page_content for doc in retrieved_docs]\n          # Re-ranking\n          relevant_docs = RERANKER.rerank(user_query, retrieved_docs, k=5)\n          relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n\n      elif compression_filter and not reranking:\n          # Compression filter\n          compressed_docs = compression_retriever.invoke(user_query)\n          relevant_docs = [doc.page_content for doc in compressed_docs]\n\n      elif compression_filter and reranking:\n          compressed_docs = compression_retriever_1.invoke(user_query)\n          relevant_docs = [doc.page_content for doc in compressed_docs]\n          relevant_docs = RERANKER.rerank(user_query, relevant_docs, k=5)\n          relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n      context = \"\\nExtracted documents:\\n\"\n      context += \"\".join([f\"\\nDocument {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)])\n\n      final_prompt = RAG_PROMPT_TEMPLATE.format(question=user_query, context=context)\n      answer = llm_pipeline(final_prompt)[0][\"generated_text\"]\n      answer = answer.split(\"<|end_header_id|>\")[-1]\n    \n        \n    return answer\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:01:10.990604Z","iopub.execute_input":"2024-05-09T15:01:10.991191Z","iopub.status.idle":"2024-05-09T15:01:13.047519Z","shell.execute_reply.started":"2024-05-09T15:01:10.991162Z","shell.execute_reply":"2024-05-09T15:01:13.046744Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Open the Excel file\nworkbook = openpyxl.load_workbook('/kaggle/input/rag-dataset-1/Evaluation_data.xlsx')\nsheet_name = \"Espnet\"\nsheet = workbook[sheet_name]\nprint(sheet)\n\n# Initialize output dictionary\noutput = {}\n\n# Iterate through rows in the first sheet\nfor row in sheet.iter_rows(min_row=2, values_only=True):  # Skip header row\n#     print(row)\n    user_query = row[1]  # Assuming the first column is the user query\n    print(user_query)\n    chat_gpt_answer = row[2]\n#     print(chat_gpt_answer)\n    output[user_query] = {\n        \"chat_gpt_answer\": chat_gpt_answer,\n        \"llm_without_rag\": writing_in_json(reranking=True, compression_filter=False, search_type='similarity', user_query=user_query,want_to_see_llm_response_without_rag = True),\n        \"rag_with_compression\": writing_in_json(reranking=False, compression_filter=True, search_type=None, user_query=user_query,want_to_see_llm_response_without_rag = False),\n        \"rag_with_rerank_similarity\": writing_in_json(reranking=True, compression_filter=False, search_type='similarity', user_query=user_query,want_to_see_llm_response_without_rag = False),\n        \"rag_with_rerank_mmr\": writing_in_json(reranking=True, compression_filter=False, search_type='mmr', user_query=user_query,want_to_see_llm_response_without_rag = False),\n        \"rag_with_compression_rerank\": writing_in_json(reranking=True, compression_filter=True, search_type='similarity', user_query=user_query,want_to_see_llm_response_without_rag = False)\n\n        }\n\n    # Write output to JSON file with sheet name as filename\n    output_filename = \"/kaggle/working/Espnet.json\"\n    with open(output_filename, \"w\") as f:\n        json.dump(output, f, indent=4)\n\n# Close the workbook\nworkbook.close()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T15:02:48.347111Z","iopub.execute_input":"2024-05-09T15:02:48.347484Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"<Worksheet \"Espnet\">\nWhat is the main focus of the ESPnet toolkit introduced in the paper?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.68it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.60it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 15.57it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Which neural network toolkits are utilized as the main deep learning engine in ESPnet?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.36it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1100, in emit\n    msg = self.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 943, in format\n    return fmt.format(record)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 678, in format\n    record.message = record.getMessage()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n    msg = msg % self.args\nTypeError: not all arguments converted during string formatting\nCall stack:\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_34/1415840603.py\", line 19, in <module>\n    \"llm_without_rag\": writing_in_json(reranking=True, compression_filter=False, search_type='similarity', user_query=user_query,want_to_see_llm_response_without_rag = True),\n  File \"/tmp/ipykernel_34/3801703019.py\", line 9, in writing_in_json\n    answer = llm_pipeline(user_query)[0][\"generated_text\"]\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 240, in __call__\n    return super().__call__(text_inputs, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n    logger.warning_once(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n    self.warning(*args, **kwargs)\nMessage: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\nArguments: (<class 'UserWarning'>,)\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How does ESPnet differ from other open-source ASR toolkits, such as Kaldi, in terms of architecture and functionality?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 18.27it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What are the key features of ESPnet's end-to-end ASR setup, and how do they contribute to its performance?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.38it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 17.93it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What is the significance of ESPnet's adoption of both connectionist temporal classification (CTC) and attention-based encoder-decoder network architectures?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.33it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 23.41it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How does ESPnet handle the training process, particularly regarding multiobjective learning and label smoothing techniques?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.56it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 21.43it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What are the advantages of using the warp CTC library in ESPnet, and how does it impact training efficiency?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.37it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.43it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Explain the process of joint decoding in ESPnet and its role in improving recognition accuracy.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.52it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.48it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 20.20it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How does ESPnet incorporate language models into the decoding process, and what benefits does this provide?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.50it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.71it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00, 18.14it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"What experimental results and comparisons are presented in the paper regarding the performance of ESPnet, particularly in tasks such as WSJ, CSJ, and HKUST?\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n100%|██████████| 1/1 [00:00<00:00,  3.39it/s]\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}